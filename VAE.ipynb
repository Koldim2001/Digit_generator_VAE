{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3212T5SGSzL_"
   },
   "source": [
    "## Вариационный автоэнкодер для генерации цифр схожих на датасет MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEFx1tEUfUr5"
   },
   "source": [
    "Автоэнкодер состоит из двух частей - энкодера и декодера. <br>\n",
    "Задача энкодера сжать входные данные (обычно эти данные обозначают  как **x**) с минимально возможной потерей данных и получить вектор (обычно этот сжатый вектор обозначают  как **z**).\n",
    "Задача декодера обратная: из сжатого вектора восстановить из **z** исходные данные.\n",
    "\n",
    "Традиционно автоэнкодеры используют в качестве способа уменьшения размерности \n",
    "\n",
    "![Вариационный автоэнкодер, схема](https://lilianweng.github.io/lil-log/assets/images/vae-gaussian.png)\n",
    "\n",
    "Отличие вариационного автоэнкодера от обычного заключается в способе получения вектора **z**. В вариационном автоэнкодере предполагается, что данные можно охарактеризовать несколькими переменные, которые принадлежат некоторому вероятностному распределению. Зная распределение, можно будет получать (генерировать) данные исключительно из вектора **z**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r78LVXckrwL"
   },
   "source": [
    "\n",
    "\n",
    "Репараметризацию необходимо делать т.к. операция извлечения примера из распределения не дифференцируема. Ниже написан этот способ в виде математической формулы\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*CEUvzm7vNdSh7cCBgcWxUA.png)\n",
    "\n",
    ",где $\\epsilon$ - случайный шум из нормального распределения;\n",
    "\n",
    "$\\mu$ - среднее значение, полученное от энкодера;\n",
    "\n",
    "$\\sigma$ - стандартное отклонение, полученное от энкодера;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biXWzWQtPi3d"
   },
   "source": [
    "\n",
    "\n",
    "#### Функция потери при обучении\n",
    "\n",
    "Функция потери состоит из двух  частей:\n",
    "\n",
    "1.   Потеря восстановления изображения (бинарная кросс-энтропия)\n",
    "2.   Дивергенция Кульбака-Либлера \n",
    "\n",
    "Итоговая функция потери определяется суммой этих двух функций потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4yW4ozFcz4d"
   },
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmU95imec3JE"
   },
   "source": [
    "__Создать 2 рализные модели VAE и оценить качество генерации изображений цифр. Построить картинку с плавными переходами между цифрами благодаря семплированию из латентного пространства.__\n",
    "\n",
    "Создададим 2 модели:\n",
    "1.   Создадим вариационный автоэнкодер с использованием сверток ([Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)) в энкодере (слои отвечающие за среднее и отклонение остаются полносвязными), и с развертками ([Conv2dTranspose](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d) в декодере. Размерность скрытого вектора равна двум \n",
    "\n",
    "2.  Создадим вариационный автоэнкодер с использованием сверток (Conv2d) в энкодере (слои отвечающие за среднее и отклонение остаются полносвязными), и с развертками ([Upsample](https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html#torch.nn.Upsample), [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)) в декодере. Размерность скрытого вектора равна двум. [Подробнее](https://distill.pub/2016/deconv-checkerboard/) \n",
    "\n",
    "Для построения изображения послепенного перехода цифр необходимо создать сетку из N на N изображений, где по оси Х изменяется значение первого элемента **z**, а по оси Y - второго элемента **z**. Построим такие сети для каждой построенной моделимодели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime as dt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 модель:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) = 60000\n",
      "len(val_dataset) = 10000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 500  # размер батча\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "print(\"len(train_dataset) =\", len(train_dataset))\n",
    "\n",
    "val_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "val_dataloader= torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"len(val_dataset) =\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фотки mnist - чб размером 28 на 28 пикселей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадаим класс энкодера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(FirstEncoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conv1 = nn.Sequential(                                           \n",
    "            nn.Conv2d(1, 32, kernel_size=(3,3), stride=2, padding=1),      \n",
    "             nn.BatchNorm2d(32),\n",
    "             nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),          \n",
    "             nn.BatchNorm2d(32),\n",
    "             nn.ReLU())\n",
    "            \n",
    "        self.fc_mu = nn.Sequential(\n",
    "            nn.Linear(32 * 49, self.latent_dim))\n",
    "        \n",
    "        self.fc_var = nn.Sequential(\n",
    "            nn.Linear(32 * 49, self.latent_dim))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.reshape(-1, 32*49)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_var(x)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим класс декодера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(FirstDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32*49),\n",
    "          \n",
    "        )\n",
    "        self.conv1 = nn.Sequential(\n",
    "           nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1),       \n",
    "           nn.BatchNorm2d(32),\n",
    "              nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),     \n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)       \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_decoder(x)\n",
    "        x = x.reshape(-1,32,7,7)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим класс VAE который внутри себя обращаться будет к двум другим классам FirstEncoder и FirstDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "        def __init__(self, latent_dim):\n",
    "            super(VAE, self).__init__()\n",
    "            self.latent_dim = latent_dim\n",
    "            self.encoder = FirstEncoder(latent_dim)\n",
    "            self.decoder = FirstDecoder(latent_dim)\n",
    "\n",
    "        def forward(self, x):\n",
    "            mu, logvar = self.encoder(x)\n",
    "            z = self.reparametrize(mu, logvar)\n",
    "            x_hat = self.decoder(z)\n",
    "            return x_hat, mu, logvar\n",
    "    \n",
    "    # Функция выполняющая репараметризацию\n",
    "        def reparametrize(self, mu, logvar):\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps * std + mu\n",
    "\n",
    "    # Реализация рандомного семплирования из латентного пространства для визуализации\n",
    "        def sample(self, num_samples) -> torch.Tensor:\n",
    "            z = torch.randn(num_samples,\n",
    "                            self.latent_dim)\n",
    "\n",
    "            z = z.to(self.encoder.fc_mu[0].weight.device)\n",
    "\n",
    "            samples = torch.sigmoid(self.decoder(z))\n",
    "\n",
    "            return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Hk3K3mmX-bu"
   },
   "source": [
    "Загрузим раcширение для tensorboard: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты процесса обучения будем отображать в tensorboard среде. Так как GitHub не отображает расширение jupiter tensorboard, поэтому все результаты будут сохранены в tensorboard.dev и представлены в виде ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[__РЕЗУЛЬТАТЫ TensorBoard.dev__](https://tensorboard.dev/experiment/5eQsWOPrTJyCXq3lZnSLLg/#scalars&_smoothingWeight=0.788)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19548), started 0:01:05 ago. (Use '!kill 19548' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b583460dd910768e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b583460dd910768e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200   # число эпох\n",
    "latent_dim = 2   # Размер латентного простанства\n",
    "\n",
    "# число рандомных семплов и латентного простанства для визуализации процесса обучения:\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = VAE(latent_dim).to(device)\n",
    "\n",
    "# параметры градиентного спуска и scheduler для постепенного уменьшения величины шага\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = SummaryWriter(comment = ' With ConvTranspose in the decoder part')\n",
    "\n",
    "    \n",
    "def generate_and_save_images(model, epoch, file_writer):\n",
    "    '''\n",
    "    Генерирует 16 примеров и записывает их в file_writer для\n",
    "    визуализации в tensorboard\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        predictions = model.sample(16).reshape(-1,1,28,28)\n",
    "    images = torchvision.utils.make_grid(predictions, 4)\n",
    "    file_writer.add_image(\"samples\", images, global_step=epoch)\n",
    "\n",
    "    \n",
    "# Получим результат до начала обучения - рандомный шум : \n",
    "generate_and_save_images(model, 0, summary_writer)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функции потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, x):\n",
    "    x_hat, mu, logvar = model(x)\n",
    "    ## сигмоида встроена в функцию потери\n",
    "    recons_loss = nn.functional.binary_cross_entropy_with_logits(x_hat, x, reduction='sum') \n",
    "\n",
    "    kld_loss = -0.5 * (1 + logvar - mu ** 2 - logvar.exp()).sum()\n",
    "\n",
    "    return recons_loss, kld_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приступим к обучению:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b77c2b9a71d4a15a70239f307019b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    totat_len = len(train_dataloader)\n",
    "    for step, train_x in enumerate(train_dataloader):\n",
    "        recon_loss, kld_loss = compute_loss(model, train_x[0].to(device))\n",
    "        summary_writer.add_scalar('train/recon_loss', recon_loss, global_step = epoch * totat_len + step)\n",
    "        summary_writer.add_scalar('train/kld_loss', kld_loss, global_step = epoch * totat_len + step)\n",
    "         \n",
    "        loss = recon_loss + kld_loss  # loss - сумму потерь\n",
    "\n",
    "        summary_writer.add_scalar('train/loss', loss, global_step = epoch * totat_len + step)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        losses = []\n",
    "        model.eval()\n",
    "        for test_x in val_dataloader:\n",
    "            recon_loss, kld_loss = compute_loss(model, test_x[0].to(device))\n",
    "            loss = recon_loss + kld_loss\n",
    "            losses.append(loss)\n",
    "        summary_writer.add_scalar('test/loss', torch.stack(losses).mean(), global_step=epoch)\n",
    "        generate_and_save_images(model, epoch, summary_writer)\n",
    "    scheduler.step()\n",
    "    \n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы получим на tensorboard графики изменения recons_loss, kld_loss и суммарного loss на трейне для каждого шага градиентного спуска и на тесте раз в 5 эпох генерили фотки и получали график изменения суммарного loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестового датасета получим значения средних на выходе из энкодера. Далее будем визуализировать латентное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "val_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "BATCH_SIZE = len(val_dataset)\n",
    "val_dataloader= torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "model.eval()\n",
    "for test_x in val_dataloader:\n",
    "    x_hat, mu, logvar = model(test_x[0])\n",
    "    labels = test_x[1]\n",
    "\n",
    "print(mu)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_save = mu\n",
    "logvar_save = logvar\n",
    "labels_save = labels\n",
    "lab = labels_save.numpy()\n",
    "mu_numpy = mu.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сохраним модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/model_mnist_convtranspose.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим цвета для каждой цифры, чтобы визуализировать в дальнейшем распеделение точек в латентном пространстве. Всего на тесте имеется 10000 изображений. <br>\n",
    "Посмотрим как распределено число фотографий между десятью классами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(mcolors.TABLEAU_COLORS.keys())\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "sns.countplot(x=lab);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой из 10000 фоток найдем соответствующее положение в латентном пространстве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "for i, point in enumerate(mu_numpy[:]):\n",
    "    nom = lab[i]\n",
    "    plt.scatter(point[0],point[1],color = col[nom])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что сеть смогла кластеризовать классы близко друг с другом, сем самым при наличии всего двух осей латентного пространства, модель неплохо справилась с задачей разделения классов без знания самих меток (то есть обучение без учителя)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим картинку с плавными переходами между цифрами благодаря семплированию из латентного пространства:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "N = 15\n",
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "for i in np.linspace(-2, 2, N, endpoint=True):\n",
    "    for j in np.linspace(2, -2, N, endpoint=True):\n",
    "        num += 1\n",
    "        ax = plt.subplot(N, N, num)\n",
    "        samples = torch.sigmoid(model.decoder(torch.Tensor([[i,j]]))).reshape(28,28)\n",
    "        ax.imshow(samples.detach(), cmap='gray')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем инвертирование цвета, чтобы получить черные цифры на белом фоне:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "N = 30\n",
    "plt.figure(figsize=(30, 30), dpi=200)\n",
    "for i in np.linspace(-2, 2, N, endpoint=True):\n",
    "    for j in np.linspace(2, -2, N, endpoint=True):\n",
    "        num += 1\n",
    "        ax = plt.subplot(N, N, num)\n",
    "        samples = 1 - torch.sigmoid(model.decoder(torch.Tensor([[i,j]]))).reshape(28,28)\n",
    "        ax.imshow(samples.detach(), cmap='gray')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 модель:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторно загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "print(\"len(train_dataset) =\", len(train_dataset))\n",
    "\n",
    "val_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "val_dataloader= torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"len(val_dataset) =\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс энкодера не изменился:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conv1 = nn.Sequential(                                           \n",
    "             nn.Conv2d(1, 32, kernel_size=(3,3), stride=2, padding=1),      \n",
    "             nn.BatchNorm2d(32),\n",
    "             nn.ReLU(),\n",
    "             nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),          \n",
    "             nn.BatchNorm2d(32),\n",
    "             nn.ReLU())\n",
    "\n",
    "        self.fc_mu = nn.Sequential(\n",
    "             nn.Linear(32 * 49, self.latent_dim))\n",
    "        \n",
    "        self.fc_var = nn.Sequential(\n",
    "             nn.Linear(32 * 49, self.latent_dim))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = x.reshape(-1, 32*49)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_var(x)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Декодер теперь реализуется через upsample_bilinear и свертки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32*49))\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(32, 32, kernel_size=3, padding=1)       \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.act = nn.ReLU() \n",
    "        self.conv2 = nn.Conv2d(32, 1, kernel_size=3, padding=1)   \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_decoder(x)\n",
    "        x = x.reshape(-1,32,7,7)\n",
    "        x = F.upsample_bilinear(x, size=14)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act(x)\n",
    "        x = F.upsample_bilinear(x, size=28)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим класс VAE, который внутри себя обращаться будет к двум другим классам Encoder и Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "        def __init__(self, latent_dim):\n",
    "            super(VAE, self).__init__()\n",
    "            self.latent_dim = latent_dim\n",
    "            self.encoder = Encoder(latent_dim)\n",
    "            self.decoder = Decoder(latent_dim)\n",
    "\n",
    "        def forward(self, x):\n",
    "            mu, logvar = self.encoder(x)\n",
    "            z = self.reparametrize(mu, logvar)\n",
    "            x_hat = self.decoder(z)\n",
    "            return x_hat, mu, logvar\n",
    "    \n",
    "    # Функция выполняющая репараметризацию\n",
    "        def reparametrize(self, mu, logvar):\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps * std + mu\n",
    "\n",
    "        def sample(self, num_samples) -> torch.Tensor:\n",
    "            z = torch.randn(num_samples,\n",
    "                            self.latent_dim)\n",
    "\n",
    "            z = z.to(self.encoder.fc_mu[0].weight.device)\n",
    "\n",
    "            samples = torch.sigmoid(self.decoder(z))\n",
    "\n",
    "            return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200   # число эпох\n",
    "latent_dim = 2  # Размер латентного простанства\n",
    "num_examples_to_generate = 16  \n",
    "\n",
    "# число рандомных семплов и латентного простанства для визуализации процесса обучения:\n",
    "model = VAE(latent_dim).to(device)\n",
    "\n",
    "# параметры градиентного спуска и scheduler для постепенного уменьшения величины шага\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = SummaryWriter(comment = ' With Upsampling in the decoder part')\n",
    "\n",
    "# Получим результат до начала обучения - рандомный шум :     \n",
    "generate_and_save_images(model, 0, summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    totat_len = len(train_dataloader)\n",
    "    for step, train_x in enumerate(train_dataloader):\n",
    "        recon_loss, kld_loss = compute_loss(model, train_x[0].to(device))\n",
    "        summary_writer.add_scalar('train/recon_loss', recon_loss, global_step = epoch * totat_len + step)\n",
    "        summary_writer.add_scalar('train/kld_loss', kld_loss, global_step = epoch * totat_len + step)\n",
    "        loss = recon_loss + kld_loss\n",
    "\n",
    "        summary_writer.add_scalar('train/loss', loss, global_step = epoch * totat_len + step)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        losses = []\n",
    "        model.eval()\n",
    "        for test_x in val_dataloader:\n",
    "            recon_loss, kld_loss = compute_loss(model, test_x[0].to(device))\n",
    "            loss = recon_loss + kld_loss\n",
    "            losses.append(loss)\n",
    "        summary_writer.add_scalar('test/loss', torch.stack(losses).mean(), global_step=epoch)\n",
    "        generate_and_save_images(model, epoch, summary_writer)\n",
    "    scheduler.step()\n",
    "    \n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы получим на tensorboard графики изменения recons_loss, kld_loss и суммарного loss на трейне для каждого шага градиентного спуска и на тесте раз в 5 эпох генерили фотки и получали график изменения суммарного loss\n",
    "\n",
    "Для тестового датасета получим значения средних на выходе из энкодера. Далее будем визуализировать латентное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "val_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "print(\"len(val_dataset) =\", len(val_dataset))\n",
    "\n",
    "BATCH_SIZE = len(val_dataset)\n",
    "val_dataloader= torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "model.eval()\n",
    "for test_x in val_dataloader:\n",
    "    x_hat, mu, logvar = model(test_x[0])\n",
    "    labels = test_x[1]\n",
    "    \n",
    "print(mu)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_save = mu\n",
    "logvar_save = logvar\n",
    "labels_save = labels\n",
    "lab = labels_save.numpy()\n",
    "mu_numpy = mu.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сохраним модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/model_mnist_upsampling.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой из 10000 фоток найдем соответствующее положение в латентном пространстве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "for i, point in enumerate(mu_numpy[:]):\n",
    "    nom = lab[i]\n",
    "    plt.scatter(point[0],point[1],color = col[nom])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что сеть смогла кластеризовать классы близко друг с другом, сем самым при наличии всего двух осей латентного пространства, модель неплохо справилась с задачей разделения классов без знания самих меток (то есть обучение без учителя)\n",
    "\n",
    "Построим картинку с плавными переходами между цифрами благодаря семплированию из латентного пространства:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "N = 30\n",
    "plt.figure(figsize=(30, 30), dpi=200)\n",
    "for i in np.linspace(-2, 2, N, endpoint=True):\n",
    "    for j in np.linspace(2, -2, N, endpoint=True):\n",
    "        num += 1\n",
    "        ax = plt.subplot(N, N, num)\n",
    "        samples = 1 - torch.sigmoid(model.decoder(torch.Tensor([[i,j]]))).reshape(28,28)\n",
    "        ax.imshow(samples.detach(), cmap='gray')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузил через терминал рузультат tensorboard:\n",
    "'''\n",
    "tensorboard dev upload --logdir logs \\\n",
    "    --name \"experiment\" \\\n",
    "    --description \"200 epochs VAE\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ВЫВОД:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
